{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning Fundamentals - LU04 Lab Exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Import required package and load data from file into pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Import the data using the file path\n",
    "data = pd.read_csv('Ames_Housing_Sales.csv', sep=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Data Preparation\n",
    "Extract the label column containing the SalePrice and remove from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_col_name = 'SalePrice'\n",
    "y_data = data[y_col_name]\n",
    "\n",
    "x_data = data.drop(y_col_name, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform One-Hot Encoding on all categorical data columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Alley_Grvl  Alley_None  Alley_Pave  BldgType_1Fam  BldgType_2fmCon  \\\n",
      "0              0           1           0              1                0   \n",
      "1              0           1           0              1                0   \n",
      "2              0           1           0              1                0   \n",
      "3              0           1           0              1                0   \n",
      "4              0           1           0              1                0   \n",
      "...          ...         ...         ...            ...              ...   \n",
      "1354           1           0           0              1                0   \n",
      "1355           0           1           0              1                0   \n",
      "1356           0           1           0              1                0   \n",
      "1357           0           1           0              1                0   \n",
      "1358           0           1           0              1                0   \n",
      "\n",
      "      BldgType_Duplex  BldgType_Twnhs  BldgType_TwnhsE  BsmtCond_Fa  \\\n",
      "0                   0               0                0            0   \n",
      "1                   0               0                0            0   \n",
      "2                   0               0                0            0   \n",
      "3                   0               0                0            0   \n",
      "4                   0               0                0            0   \n",
      "...               ...             ...              ...          ...   \n",
      "1354                0               0                0            0   \n",
      "1355                0               0                0            0   \n",
      "1356                0               0                0            0   \n",
      "1357                0               0                0            0   \n",
      "1358                0               0                0            0   \n",
      "\n",
      "      BsmtCond_Gd  ...  SaleType_ConLD  SaleType_ConLI  SaleType_ConLw  \\\n",
      "0               0  ...               0               0               0   \n",
      "1               0  ...               0               0               0   \n",
      "2               0  ...               0               0               0   \n",
      "3               1  ...               0               0               0   \n",
      "4               0  ...               0               0               0   \n",
      "...           ...  ...             ...             ...             ...   \n",
      "1354            0  ...               0               0               0   \n",
      "1355            0  ...               0               0               0   \n",
      "1356            0  ...               0               0               0   \n",
      "1357            0  ...               0               0               0   \n",
      "1358            0  ...               0               0               0   \n",
      "\n",
      "      SaleType_New  SaleType_Oth  SaleType_WD  Street_Grvl  Street_Pave  \\\n",
      "0                0             0            1            0            1   \n",
      "1                0             0            1            0            1   \n",
      "2                0             0            1            0            1   \n",
      "3                0             0            1            0            1   \n",
      "4                0             0            1            0            1   \n",
      "...            ...           ...          ...          ...          ...   \n",
      "1354             0             0            1            0            1   \n",
      "1355             0             0            1            0            1   \n",
      "1356             0             0            1            0            1   \n",
      "1357             0             0            0            0            1   \n",
      "1358             0             0            1            0            1   \n",
      "\n",
      "      Utilities_AllPub  Utilities_NoSeWa  \n",
      "0                    1                 0  \n",
      "1                    1                 0  \n",
      "2                    1                 0  \n",
      "3                    1                 0  \n",
      "4                    1                 0  \n",
      "...                ...               ...  \n",
      "1354                 1                 0  \n",
      "1355                 1                 0  \n",
      "1356                 1                 0  \n",
      "1357                 1                 0  \n",
      "1358                 1                 0  \n",
      "\n",
      "[1359 rows x 258 columns]\n"
     ]
    }
   ],
   "source": [
    "# OneHot Encode categorical data\n",
    "categorical_data = x_data.select_dtypes(include=['object']).copy()\n",
    "for col in categorical_data.columns:\n",
    "    categorical_data[col] = categorical_data[col].astype('category')\n",
    "categorical_data = pd.get_dummies(categorical_data)\n",
    "print(categorical_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalize data scales for numerical data and the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard Scale numerial feature data\n",
    "numerical_data = x_data.select_dtypes(include=['float64', 'int64']).copy()\n",
    "data_tmp = numerical_data.values #returns a numpy array\n",
    "std_scaler = StandardScaler()\n",
    "data_tmp = std_scaler.fit_transform(data_tmp)\n",
    "numerical_data = pd.DataFrame(data_tmp, columns=numerical_data.columns)\n",
    "\n",
    "# Standard Scale numerial label data\n",
    "y_tmp = pd.DataFrame(y_data).values #returns a numpy array\n",
    "y_scaler = MinMaxScaler()\n",
    "y_tmp = y_scaler.fit_transform(y_tmp)\n",
    "y_tmp = y_tmp.reshape(-1)\n",
    "y_data = pd.Series(y_tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine categorial and numerical data\n",
    "x_data = pd.concat([numerical_data, categorical_data], axis=1)\n",
    "x_col_name = x_data.columns\n",
    "x_col_count = len(x_col_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 Train, Validation, Test Dataset Split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3.1 Method 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (951, 294)\n",
      "y_train shape: (951,)\n",
      "X_test shape: (408, 294)\n",
      "y_test shape: (408,)\n",
      "Epoch 1/20\n",
      "95/95 [==============================] - 1s 3ms/step - loss: 0.0337 - mse: 0.0337 - val_loss: 0.0187 - val_mse: 0.0187\n",
      "Epoch 2/20\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 0.0127 - mse: 0.0127 - val_loss: 0.0118 - val_mse: 0.0118\n",
      "Epoch 3/20\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 0.0091 - mse: 0.0091 - val_loss: 0.0094 - val_mse: 0.0094\n",
      "Epoch 4/20\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 0.0076 - mse: 0.0076 - val_loss: 0.0081 - val_mse: 0.0081\n",
      "Epoch 5/20\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 0.0067 - mse: 0.0067 - val_loss: 0.0072 - val_mse: 0.0072\n",
      "Epoch 6/20\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 0.0061 - mse: 0.0061 - val_loss: 0.0067 - val_mse: 0.0067\n",
      "Epoch 7/20\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 0.0057 - mse: 0.0057 - val_loss: 0.0062 - val_mse: 0.0062\n",
      "Epoch 8/20\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 0.0053 - mse: 0.0053 - val_loss: 0.0059 - val_mse: 0.0059\n",
      "Epoch 9/20\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 0.0050 - mse: 0.0050 - val_loss: 0.0057 - val_mse: 0.0057\n",
      "Epoch 10/20\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 0.0048 - mse: 0.0048 - val_loss: 0.0056 - val_mse: 0.0056\n",
      "Epoch 11/20\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 0.0046 - mse: 0.0046 - val_loss: 0.0054 - val_mse: 0.0054\n",
      "Epoch 12/20\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 0.0045 - mse: 0.0045 - val_loss: 0.0053 - val_mse: 0.0053\n",
      "Epoch 13/20\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 0.0043 - mse: 0.0043 - val_loss: 0.0051 - val_mse: 0.0051\n",
      "Epoch 14/20\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 0.0042 - mse: 0.0042 - val_loss: 0.0050 - val_mse: 0.0050\n",
      "Epoch 15/20\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 0.0041 - mse: 0.0041 - val_loss: 0.0049 - val_mse: 0.0049\n",
      "Epoch 16/20\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 0.0040 - mse: 0.0040 - val_loss: 0.0049 - val_mse: 0.0049\n",
      "Epoch 17/20\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 0.0039 - mse: 0.0039 - val_loss: 0.0048 - val_mse: 0.0048\n",
      "Epoch 18/20\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 0.0038 - mse: 0.0038 - val_loss: 0.0047 - val_mse: 0.0047\n",
      "Epoch 19/20\n",
      "95/95 [==============================] - 0s 2ms/step - loss: 0.0037 - mse: 0.0037 - val_loss: 0.0046 - val_mse: 0.0046\n",
      "Epoch 20/20\n",
      "95/95 [==============================] - 0s 1ms/step - loss: 0.0036 - mse: 0.0036 - val_loss: 0.0045 - val_mse: 0.0045\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0039 - mse: 0.0039\n",
      "Test loss: 0.0039\n",
      "Test error: 0.0039\n"
     ]
    }
   ],
   "source": [
    "# Split data into train-test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_data, y_data, test_size=0.3)\n",
    "print('X_train shape: {}'.format(X_train.shape))\n",
    "print('y_train shape: {}'.format(y_train.shape))\n",
    "print('X_test shape: {}'.format(X_test.shape))\n",
    "print('y_test shape: {}'.format(y_test.shape))\n",
    "\n",
    "network = models.Sequential()\n",
    "\n",
    "# This is 1 input layer of x_col_count nodes and 1 output later of 1 node\n",
    "#network.add(layers.Dense(1, activation='sigmoid', input_shape=(x_col_count,)))\n",
    "\n",
    "# >>>>>>>>> the following set is a sample if to create multiple layer >>>>>>>>>>>>>\n",
    "#example to create multiple layers. the following example is \n",
    "# 1 input layer of x_col_count nodes \n",
    "# 2 hidden layers of 5 and 3 nodes respectively\n",
    "# 1 output layer of 1 node on predicted sales pricing\n",
    "network.add(layers.Dense(5, activation='relu', input_shape=(x_col_count,)))\n",
    "network.add(layers.Dense(3, activation='relu'))\n",
    "network.add(layers.Dense(1, activation='sigmoid'))\n",
    "# <<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
    "\n",
    "# Observe the use loss function in the codes below\n",
    "network.compile(optimizer='sgd', loss='mean_squared_error', metrics=['mse'])\n",
    "\n",
    "# Observe the setting of shuffle to True\n",
    "# Play around the epochs, batch_size to see the effect \n",
    "# (Try to achieve <0.001 loss)\n",
    "network.fit(X_train, y_train, epochs=20, batch_size=8, validation_split=0.2, shuffle=True)\n",
    "\n",
    "test_loss, test_error = network.evaluate(X_test, y_test)\n",
    "print('Test loss: {:.4f}'.format(test_loss))\n",
    "print('Test error: {:.4f}'.format(test_error))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3.2 Method 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (815, 294)\n",
      "y_train shape: (815,)\n",
      "X_val shape: (272, 294)\n",
      "y_val shape: (272,)\n",
      "X_test shape: (272, 294)\n",
      "y_test shape: (272,)\n",
      "Epoch 1/20\n",
      "102/102 [==============================] - 1s 3ms/step - loss: 0.0920 - mae: 0.2826 - val_loss: 0.0769 - val_mae: 0.2583\n",
      "Epoch 2/20\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.0571 - mae: 0.2190 - val_loss: 0.0437 - val_mae: 0.1879\n",
      "Epoch 3/20\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.0306 - mae: 0.1532 - val_loss: 0.0209 - val_mae: 0.1267\n",
      "Epoch 4/20\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.0168 - mae: 0.1057 - val_loss: 0.0114 - val_mae: 0.0904\n",
      "Epoch 5/20\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.0115 - mae: 0.0819 - val_loss: 0.0079 - val_mae: 0.0733\n",
      "Epoch 6/20\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.0092 - mae: 0.0702 - val_loss: 0.0062 - val_mae: 0.0631\n",
      "Epoch 7/20\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.0079 - mae: 0.0630 - val_loss: 0.0052 - val_mae: 0.0564\n",
      "Epoch 8/20\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.0070 - mae: 0.0580 - val_loss: 0.0046 - val_mae: 0.0521\n",
      "Epoch 9/20\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.0063 - mae: 0.0544 - val_loss: 0.0041 - val_mae: 0.0485\n",
      "Epoch 10/20\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.0058 - mae: 0.0514 - val_loss: 0.0038 - val_mae: 0.0459\n",
      "Epoch 11/20\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.0055 - mae: 0.0494 - val_loss: 0.0036 - val_mae: 0.0438\n",
      "Epoch 12/20\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.0052 - mae: 0.0478 - val_loss: 0.0034 - val_mae: 0.0423\n",
      "Epoch 13/20\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.0050 - mae: 0.0466 - val_loss: 0.0032 - val_mae: 0.0410\n",
      "Epoch 14/20\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.0049 - mae: 0.0456 - val_loss: 0.0031 - val_mae: 0.0400\n",
      "Epoch 15/20\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.0048 - mae: 0.0448 - val_loss: 0.0030 - val_mae: 0.0391\n",
      "Epoch 16/20\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.0046 - mae: 0.0441 - val_loss: 0.0029 - val_mae: 0.0383\n",
      "Epoch 17/20\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.0045 - mae: 0.0435 - val_loss: 0.0028 - val_mae: 0.0376\n",
      "Epoch 18/20\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.0045 - mae: 0.0429 - val_loss: 0.0028 - val_mae: 0.0371\n",
      "Epoch 19/20\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.0044 - mae: 0.0423 - val_loss: 0.0027 - val_mae: 0.0366\n",
      "Epoch 20/20\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.0043 - mae: 0.0419 - val_loss: 0.0027 - val_mae: 0.0361\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0032 - mae: 0.0403\n",
      "Test loss: 0.0032\n",
      "Test mae: 0.0403\n"
     ]
    }
   ],
   "source": [
    "# Split data into train-test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_data, y_data, test_size=0.4)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=0.5)\n",
    "print('X_train shape: {}'.format(X_train.shape))\n",
    "print('y_train shape: {}'.format(y_train.shape))\n",
    "print('X_val shape: {}'.format(X_val.shape))\n",
    "print('y_val shape: {}'.format(y_val.shape))\n",
    "print('X_test shape: {}'.format(X_test.shape))\n",
    "print('y_test shape: {}'.format(y_test.shape))\n",
    "\n",
    "network = models.Sequential()\n",
    "\n",
    "# This is 1 input layer of x_col_count nodes and 1 output later of 1 node\n",
    "#network.add(layers.Dense(1, activation='sigmoid', input_shape=(x_col_count,)))\n",
    "\n",
    "# >>>>>>>>> the following set is a sample if to create multiple layer >>>>>>>>>>>>>\n",
    "#example to create multiple layers. the following example is \n",
    "# 1 input layer of x_col_count nodes \n",
    "# 2 hidden layers of 5 and 3 nodes respectively\n",
    "# 1 output layer of 1 node on predicted sales pricing\n",
    "network.add(layers.Dense(5, activation='relu', input_shape=(x_col_count,)))\n",
    "network.add(layers.Dense(3, activation='relu'))\n",
    "network.add(layers.Dense(1, activation='sigmoid'))\n",
    "# <<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
    "\n",
    "# Observe the use loss function in the codes below\n",
    "network.compile(optimizer='sgd', loss='mean_squared_error', metrics=['mae'])\n",
    "\n",
    "# Observe the setting of shuffle to True\n",
    "# Play around the epochs, batch_size to see the effect \n",
    "# (Try to achieve <0.001 loss)\n",
    "history = network.fit(X_train, y_train, epochs=20, batch_size=8, validation_data=(X_val, y_val), shuffle=True)\n",
    "\n",
    "test_loss, test_mae = network.evaluate(X_test, y_test)\n",
    "print('Test loss: {:.4f}'.format(test_loss))\n",
    "print('Test mae: {:.4f}'.format(test_mae))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3.3 K-fold cross validation using scikit-learn\n",
    "\n",
    "The following is a simple k-fold implementation. all data preparation will still be required prior this cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "network2 = models.Sequential()\n",
    "\n",
    "# >>>>>>>>> the following set is a sample if to create multiple layer >>>>>>>>>>>>>\n",
    "#example to create multiple layers. the following example is \n",
    "# 1 input layer of x_col_count nodes \n",
    "# 2 hidden layers of 5 and 3 nodes respectively\n",
    "# 1 output layer of 1 node on predicted sales pricing\n",
    "network2.add(layers.Dense(5, activation='relu', input_shape=(x_col_count,)))\n",
    "network2.add(layers.Dense(3, activation='relu'))\n",
    "network2.add(layers.Dense(1, activation='sigmoid'))\n",
    "# <<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
    "\n",
    "# Observe the use loss function in the codes below\n",
    "network2.compile(optimizer='sgd', loss='mean_squared_error', metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************************** Running fold 0\n",
      "=====Training set=======\n",
      "Train set from 2 with total of  1087\n",
      "[   2    3    4 ... 1354 1355 1357]\n",
      "=====Testing set=======\n",
      "Test set from 0 with total of  272\n",
      "[   0    1   14   26   28   30   34   35   42   49   50   56   62   71\n",
      "   79   81   82   84   85   86   90   93   95  110  111  132  136  137\n",
      "  141  143  144  152  154  163  168  169  181  188  192  198  203  204\n",
      "  213  215  217  222  223  236  237  240  246  254  256  262  270  271\n",
      "  275  277  279  283  284  287  304  307  316  323  325  337  345  360\n",
      "  365  369  376  379  380  383  386  390  396  404  407  408  410  415\n",
      "  417  423  426  435  445  449  450  464  466  467  468  471  481  482\n",
      "  485  486  488  498  503  504  512  520  526  534  547  555  560  563\n",
      "  564  569  571  581  591  607  609  619  625  628  629  631  635  637\n",
      "  651  653  659  661  663  668  685  689  693  700  703  704  715  722\n",
      "  729  730  735  739  741  743  746  747  750  767  776  786  796  807\n",
      "  808  810  814  816  818  819  821  823  824  827  828  830  840  843\n",
      "  848  849  851  861  870  872  877  882  883  899  900  902  917  919\n",
      "  921  922  924  934  945  947  951  952  954  958  960  962  966  971\n",
      "  980  992 1002 1004 1005 1009 1010 1013 1017 1019 1024 1026 1029 1030\n",
      " 1042 1050 1056 1065 1074 1075 1077 1085 1089 1090 1092 1093 1094 1097\n",
      " 1099 1104 1106 1107 1108 1118 1119 1125 1126 1135 1144 1155 1157 1163\n",
      " 1165 1171 1172 1179 1181 1184 1193 1199 1200 1201 1207 1221 1222 1228\n",
      " 1244 1249 1252 1256 1259 1261 1270 1283 1289 1295 1299 1300 1312 1318\n",
      " 1339 1346 1347 1348 1356 1358]\n",
      "Epoch 1/5\n",
      "136/136 [==============================] - 1s 2ms/step - loss: 0.0956 - mae: 0.2911\n",
      "Epoch 2/5\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 0.0621 - mae: 0.2331\n",
      "Epoch 3/5\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 0.0457 - mae: 0.1973\n",
      "Epoch 4/5\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 0.0336 - mae: 0.1667\n",
      "Epoch 5/5\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 0.0241 - mae: 0.1382\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0034 - mae: 0.0381\n",
      "Test error: 0.03813166543841362\n",
      "********************************** Running fold 1\n",
      "=====Training set=======\n",
      "Train set from 0 with total of  1087\n",
      "[   0    1    4 ... 1356 1357 1358]\n",
      "=====Testing set=======\n",
      "Test set from 2 with total of  272\n",
      "[   2    3    8    9   18   20   27   29   31   33   43   64   70   91\n",
      "   98  100  104  106  108  112  122  128  135  145  147  158  161  164\n",
      "  170  174  176  185  193  194  196  197  199  202  209  232  235  239\n",
      "  243  248  252  261  263  266  269  272  274  281  285  286  296  303\n",
      "  309  310  315  318  326  329  331  335  336  340  341  342  343  348\n",
      "  352  357  358  361  363  366  370  374  387  388  401  411  414  416\n",
      "  425  436  437  438  442  446  452  453  454  462  474  487  490  492\n",
      "  493  494  501  502  519  530  532  535  538  554  557  565  577  583\n",
      "  585  596  597  599  602  605  606  615  617  618  622  623  630  632\n",
      "  638  644  645  649  660  671  678  679  682  683  686  690  697  699\n",
      "  708  723  724  725  726  731  737  738  740  753  754  757  758  759\n",
      "  768  775  777  782  784  787  795  800  801  822  831  834  837  846\n",
      "  847  853  858  863  868  869  875  876  880  881  888  892  894  903\n",
      "  905  910  913  914  916  926  927  935  942  949  953  961  968  970\n",
      "  975  976  984  989  991  994  998 1006 1014 1020 1023 1025 1027 1028\n",
      " 1036 1038 1039 1041 1051 1054 1055 1058 1067 1072 1078 1081 1082 1087\n",
      " 1101 1102 1120 1122 1127 1128 1130 1136 1141 1154 1160 1161 1162 1166\n",
      " 1169 1174 1186 1187 1194 1209 1211 1213 1214 1216 1219 1220 1230 1234\n",
      " 1236 1237 1240 1241 1242 1246 1260 1262 1271 1276 1280 1297 1298 1314\n",
      " 1316 1319 1322 1334 1349 1351]\n",
      "Epoch 1/5\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 0.0180 - mae: 0.1161\n",
      "Epoch 2/5\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 0.0134 - mae: 0.0958\n",
      "Epoch 3/5\n",
      "136/136 [==============================] - 0s 968us/step - loss: 0.0108 - mae: 0.0817\n",
      "Epoch 4/5\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 0.0092 - mae: 0.0723\n",
      "Epoch 5/5\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 0.0081 - mae: 0.0656\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0047 - mae: 0.0423\n",
      "Test error: 0.04233415424823761\n",
      "********************************** Running fold 2\n",
      "=====Training set=======\n",
      "Train set from 0 with total of  1087\n",
      "[   0    1    2 ... 1356 1357 1358]\n",
      "=====Testing set=======\n",
      "Test set from 6 with total of  272\n",
      "[   6   12   13   15   16   19   39   41   46   51   53   54   65   66\n",
      "   68   72   92  113  114  116  118  119  120  125  129  133  139  140\n",
      "  148  153  155  157  159  166  167  171  172  186  191  200  212  214\n",
      "  216  220  221  225  238  253  257  267  268  276  280  282  291  292\n",
      "  298  299  306  308  312  314  319  322  324  328  332  334  339  346\n",
      "  350  351  353  359  362  367  368  371  373  378  381  385  391  393\n",
      "  398  406  409  412  418  420  422  428  432  439  447  451  455  457\n",
      "  459  463  473  475  476  478  484  505  511  523  524  525  527  528\n",
      "  537  548  549  550  552  556  558  568  574  608  611  613  620  621\n",
      "  624  627  634  636  640  643  650  652  654  655  656  666  670  672\n",
      "  677  687  702  706  711  713  716  718  720  721  733  736  744  751\n",
      "  756  760  762  765  770  771  780  781  790  793  794  798  799  806\n",
      "  811  820  854  859  862  871  873  874  878  895  896  898  907  908\n",
      "  918  923  928  932  936  940  943  944  948  956  957  965  967  973\n",
      "  977  978  983  988  990  993  995 1000 1001 1011 1021 1033 1035 1037\n",
      " 1043 1045 1047 1052 1064 1070 1071 1076 1080 1095 1100 1110 1116 1137\n",
      " 1138 1146 1147 1148 1151 1156 1159 1164 1167 1168 1173 1175 1176 1182\n",
      " 1189 1190 1192 1197 1203 1217 1218 1223 1224 1232 1239 1243 1250 1253\n",
      " 1257 1263 1268 1277 1284 1285 1290 1302 1308 1309 1315 1323 1327 1328\n",
      " 1333 1336 1338 1341 1342 1355]\n",
      "Epoch 1/5\n",
      "136/136 [==============================] - 0s 997us/step - loss: 0.0075 - mae: 0.0609\n",
      "Epoch 2/5\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 0.0069 - mae: 0.0573\n",
      "Epoch 3/5\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 0.0063 - mae: 0.0542\n",
      "Epoch 4/5\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 0.0057 - mae: 0.0516\n",
      "Epoch 5/5\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 0.0051 - mae: 0.0489\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0033 - mae: 0.0396\n",
      "Test error: 0.039627280086278915\n",
      "********************************** Running fold 3\n",
      "=====Training set=======\n",
      "Train set from 0 with total of  1087\n",
      "[   0    1    2 ... 1356 1357 1358]\n",
      "=====Testing set=======\n",
      "Test set from 4 with total of  272\n",
      "[   4    5   10   11   22   23   25   36   37   38   44   45   47   48\n",
      "   63   74   75   77   78   96   97  101  102  103  107  109  121  126\n",
      "  142  146  149  150  151  173  175  177  180  182  183  189  190  195\n",
      "  218  227  228  229  230  233  251  255  259  260  264  265  273  290\n",
      "  293  295  301  313  321  330  333  338  344  356  372  382  389  392\n",
      "  394  395  397  399  402  403  413  419  421  429  430  431  440  441\n",
      "  444  448  458  460  461  470  472  495  496  507  508  514  515  516\n",
      "  517  518  521  522  531  533  536  539  540  541  545  551  559  561\n",
      "  566  570  572  578  579  584  588  589  593  594  600  601  610  612\n",
      "  614  616  633  641  642  646  647  658  662  669  673  674  675  680\n",
      "  681  684  691  694  705  707  709  712  727  734  745  749  752  755\n",
      "  761  763  764  766  769  772  773  774  779  788  789  791  792  797\n",
      "  802  803  805  817  829  833  835  836  838  844  845  852  866  879\n",
      "  884  886  887  889  890  891  897  904  920  929  930  937  955  963\n",
      "  972  974  985  987  996  997 1003 1022 1034 1040 1044 1053 1060 1061\n",
      " 1063 1066 1068 1069 1073 1079 1083 1084 1086 1088 1098 1103 1109 1111\n",
      " 1112 1117 1123 1124 1129 1133 1134 1140 1150 1152 1153 1170 1178 1183\n",
      " 1185 1188 1191 1198 1205 1208 1210 1212 1226 1245 1247 1251 1254 1266\n",
      " 1267 1272 1273 1274 1278 1282 1293 1301 1303 1304 1306 1313 1317 1320\n",
      " 1321 1325 1337 1344 1345 1353]\n",
      "Epoch 1/5\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 0.0050 - mae: 0.0470\n",
      "Epoch 2/5\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 0.0044 - mae: 0.0444\n",
      "Epoch 3/5\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 0.0038 - mae: 0.0421\n",
      "Epoch 4/5\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 0.0034 - mae: 0.0400\n",
      "Epoch 5/5\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.0032 - mae: 0.0385\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.0030 - mae: 0.0390\n",
      "Test error: 0.038977112621068954\n",
      "********************************** Running fold 4\n",
      "=====Training set=======\n",
      "Train set from 0 with total of  1088\n",
      "[   0    1    2 ... 1355 1356 1358]\n",
      "=====Testing set=======\n",
      "Test set from 7 with total of  271\n",
      "[   7   17   21   24   32   40   52   55   57   58   59   60   61   67\n",
      "   69   73   76   80   83   87   88   89   94   99  105  115  117  123\n",
      "  124  127  130  131  134  138  156  160  162  165  178  179  184  187\n",
      "  201  205  206  207  208  210  211  219  224  226  231  234  241  242\n",
      "  244  245  247  249  250  258  278  288  289  294  297  300  302  305\n",
      "  311  317  320  327  347  349  354  355  364  375  377  384  400  405\n",
      "  424  427  433  434  443  456  465  469  477  479  480  483  489  491\n",
      "  497  499  500  506  509  510  513  529  542  543  544  546  553  562\n",
      "  567  573  575  576  580  582  586  587  590  592  595  598  603  604\n",
      "  626  639  648  657  664  665  667  676  688  692  695  696  698  701\n",
      "  710  714  717  719  728  732  742  748  778  783  785  804  809  812\n",
      "  813  815  825  826  832  839  841  842  850  855  856  857  860  864\n",
      "  865  867  885  893  901  906  909  911  912  915  925  931  933  938\n",
      "  939  941  946  950  959  964  969  979  981  982  986  999 1007 1008\n",
      " 1012 1015 1016 1018 1031 1032 1046 1048 1049 1057 1059 1062 1091 1096\n",
      " 1105 1113 1114 1115 1121 1131 1132 1139 1142 1143 1145 1149 1158 1177\n",
      " 1180 1195 1196 1202 1204 1206 1215 1225 1227 1229 1231 1233 1235 1238\n",
      " 1248 1255 1258 1264 1265 1269 1275 1279 1281 1286 1287 1288 1291 1292\n",
      " 1294 1296 1305 1307 1310 1311 1324 1326 1329 1330 1331 1332 1335 1340\n",
      " 1343 1350 1352 1354 1357]\n",
      "Epoch 1/5\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.0034 - mae: 0.0379\n",
      "Epoch 2/5\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.0032 - mae: 0.0371\n",
      "Epoch 3/5\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.0031 - mae: 0.0367\n",
      "Epoch 4/5\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.0030 - mae: 0.0361\n",
      "Epoch 5/5\n",
      "136/136 [==============================] - 0s 1ms/step - loss: 0.0029 - mae: 0.0357\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0043 - mae: 0.0422\n",
      "Test error: 0.042162880301475525\n"
     ]
    }
   ],
   "source": [
    "from numpy import array\n",
    "\n",
    "# implement k-fold using scikit learn library. you can refer to the link below on the api\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# prepare cross validation of 5 fold on the data and further shuffle the data. You can modify this to \n",
    "# see the data set used in the print out \n",
    "kf = KFold(n_splits=5, random_state=40, shuffle=True)\n",
    "\n",
    "for i, (train_index, test_index) in enumerate(kf.split(x_data)):\n",
    "    firstTrain = train_index[0] \n",
    "    totalTrainRec = len(train_index)\n",
    "    firstTest = test_index[0] \n",
    "    totalTestRec = len(test_index)\n",
    "    \n",
    "    print('********************************** Running fold '+ str(i))  \n",
    "    print('=====Training set=======')\n",
    "    print('Train set from ' + str(firstTrain) + ' with total of  ' + str(totalTrainRec))\n",
    "    print(train_index)\n",
    "\n",
    "    print('=====Testing set=======')\n",
    "    print('Test set from ' + str(firstTest) + ' with total of  ' + str(totalTestRec))\n",
    "    print(test_index)\n",
    "    K_train, K_label = x_data.iloc[train_index], y_data.iloc[train_index]\n",
    "    K_test, Ktest_label = x_data.iloc[test_index], y_data.iloc[test_index]\n",
    "    \n",
    "    network2.fit(K_train, K_label, epochs=5, batch_size=8)\n",
    "    \n",
    "    test_loss, test_mae = network.evaluate(K_test, Ktest_label)\n",
    "    print('Test error: {}'.format(test_mae))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
